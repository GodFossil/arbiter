const express = require(‚Äúexpress‚Äù);
const { Client, GatewayIntentBits } = require(‚Äúdiscord.js‚Äù);
const { GoogleGenerativeAI } = require(‚Äù@google/generative-ai‚Äù);
const mongoose = require(‚Äúmongoose‚Äù);

// Import all your fact-checking services
const ClaimExtractor = require(‚Äù./services/claimExtractor‚Äù);
const FactChecker = require(‚Äù./services/factChecker‚Äù);
const SourceVerifier = require(‚Äù./services/sourceVerifier‚Äù);
const ContradictionDetector = require(‚Äù./services/contradictionDetector‚Äù);
const InteractiveVerifier = require(‚Äù./services/interactiveVerifier‚Äù);
const WebSearch = require(‚Äù./services/webSearch‚Äù);
const ContentFetcher = require(‚Äù./services/contentFetcher‚Äù);
const ThreadContextAnalyzer = require(‚Äù./services/threadContextAnalyzer‚Äù);

// Import utilities
const ConfidenceScorer = require(‚Äù./utils/confidenceScorer‚Äù);
const ErrorHandler = require(‚Äù./utils/errorHandler‚Äù);
const Logger = require(‚Äù./utils/logger‚Äù);
const CacheManager = require(‚Äù./utils/cacheManager‚Äù);
const ParallelProcessor = require(‚Äù./utils/parallelProcessor‚Äù);

// Import models
const FactCheck = require(‚Äù./models/FactCheck‚Äù);

// üåê Web server (keeps hosting platform alive)
const app = express();
app.get(‚Äù/‚Äù, (*, res) => res.send(‚ÄúArbiter is online and fact-checking with Gemini AI.‚Äù));
app.get(‚Äù/health‚Äù, (*, res) => res.json({
status: ‚Äúhealthy‚Äù,
timestamp: new Date().toISOString(),
services: ‚Äúfact-checking active‚Äù,
ai_provider: ‚ÄúGoogle Gemini‚Äù
}));
app.listen(process.env.PORT || 3000, () => console.log(‚Äúüåê Web server running.‚Äù));

// üîê Environment validation
const requiredEnvVars = [
‚ÄòDISCORD_TOKEN‚Äô,
‚ÄòGEMINI_API_KEY‚Äô,
‚ÄòMONGODB_URI‚Äô,
‚ÄòGOOGLE_SEARCH_API_KEY‚Äô // or EXA_API_KEY if using Exa
];

for (const envVar of requiredEnvVars) {
if (!process.env[envVar]) {
console.error(`‚ùå Missing required environment variable: ${envVar}`);
process.exit(1);
}
}

const DISCORD_TOKEN = process.env.DISCORD_TOKEN;
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const MONGODB_URI = process.env.MONGODB_URI;
const SEARCH_API_KEY = process.env.GOOGLE_SEARCH_API_KEY || process.env.EXA_API_KEY;

// ü§ñ Google Gemini AI Setup
const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);

// Model configurations for different use cases
const MODELS = {
// For summary, fact-checking, web searching, context verification
BACKGROUND: ‚Äúgemini-2.0-flash-exp‚Äù, // Use latest available model for background tasks
// For actual message responses (primary)
RESPONSE_PRIMARY: ‚Äúgemini-2.0-flash-exp‚Äù, // Use latest available model
// Fallback for message responses
RESPONSE_FALLBACK: ‚Äúgemini-1.5-flash‚Äù
};

// Gemini AI helper class
class GeminiAI {
constructor() {
this.backgroundModel = genAI.getGenerativeModel({
model: MODELS.BACKGROUND,
generationConfig: {
temperature: 0,
topP: 0.8,
topK: 40,
maxOutputTokens: 2048,
}
});

```
this.responseModel = genAI.getGenerativeModel({ 
  model: MODELS.RESPONSE_PRIMARY,
  generationConfig: {
    temperature: 0.7,
    topP: 0.9,
    topK: 40,
    maxOutputTokens: 1024,
  }
});

this.fallbackModel = genAI.getGenerativeModel({ 
  model: MODELS.RESPONSE_FALLBACK,
  generationConfig: {
    temperature: 0.7,
    topP: 0.9,
    topK: 40,
    maxOutputTokens: 1024,
  }
});
```

}

// For background processing (fact-checking, analysis, etc.)
async generateBackground(prompt, systemPrompt = null) {
try {
const fullPrompt = systemPrompt ? `${systemPrompt}\n\n${prompt}` : prompt;
const result = await this.backgroundModel.generateContent(fullPrompt);
return result.response.text();
} catch (error) {
console.error(‚ÄúGemini background generation error:‚Äù, error);
throw error;
}
}

// For user-facing responses with fallback
async generateResponse(prompt, systemPrompt = null) {
try {
const fullPrompt = systemPrompt ? `${systemPrompt}\n\n${prompt}` : prompt;
const result = await this.responseModel.generateContent(fullPrompt);
return result.response.text();
} catch (error) {
console.warn(‚ÄúPrimary response model failed, trying fallback:‚Äù, error.message);
try {
const fullPrompt = systemPrompt ? `${systemPrompt}\n\n${prompt}` : prompt;
const result = await this.fallbackModel.generateContent(fullPrompt);
return result.response.text();
} catch (fallbackError) {
console.error(‚ÄúBoth response models failed:‚Äù, fallbackError);
throw fallbackError;
}
}
}

// For JSON responses (fact-checking analysis)
async generateJSON(prompt, systemPrompt) {
try {
const fullPrompt = `${systemPrompt}\n\nIMPORTANT: You must respond with valid JSON only. No other text.\n\n${prompt}`;
const result = await this.backgroundModel.generateContent(fullPrompt);
const text = result.response.text().trim();

```
  // Clean up the response to extract JSON
  const jsonMatch = text.match(/\{[\s\S]*\}/);
  if (jsonMatch) {
    return JSON.parse(jsonMatch[0]);
  } else {
    return JSON.parse(text);
  }
} catch (error) {
  console.error("Gemini JSON generation error:", error);
  throw error;
}
```

}

// Convert OpenAI-style messages to Gemini prompt
convertMessagesToPrompt(messages) {
return messages.map(msg => {
if (msg.role === ‚Äòsystem‚Äô) {
return `SYSTEM: ${msg.content}`;
} else if (msg.role === ‚Äòuser‚Äô) {
return `USER: ${msg.content}`;
} else if (msg.role === ‚Äòassistant‚Äô) {
return `ASSISTANT: ${msg.content}`;
}
return msg.content;
}).join(‚Äô\n\n‚Äô);
}
}

// Initialize Gemini AI
const geminiAI = new GeminiAI();

// üß† MongoDB Setup with better error handling
mongoose.connect(MONGODB_URI, {
useNewUrlParser: true,
useUnifiedTopology: true,
}).then(() => {
console.log(‚Äú‚úÖ Connected to MongoDB‚Äù);
}).catch(err => {
console.error(‚Äú‚ùå MongoDB connection failed:‚Äù, err);
process.exit(1);
});

// Enhanced schemas
const memorySchema = new mongoose.Schema({
userId: String,
context: Array,
summary: String,
preferences: String,
factCheckHistory: [{ type: mongoose.Schema.Types.ObjectId, ref: ‚ÄòFactCheck‚Äô }],
trustScore: { type: Number, default: 1.0 },
lastActive: { type: Date, default: Date.now }
});

const channelMemorySchema = new mongoose.Schema({
channelId: String,
messages: Array,
recentClaims: Array,
flaggedMessages: Array,
lastCleaned: { type: Date, default: Date.now }
});

const Memory = mongoose.model(‚ÄúMemory‚Äù, memorySchema);
const ChannelMemory = mongoose.model(‚ÄúChannelMemory‚Äù, channelMemorySchema);

// ü§ñ Initialize services with Gemini AI
const logger = new Logger();
const errorHandler = new ErrorHandler(logger);
const cacheManager = new CacheManager();

// Initialize fact-checking pipeline with Gemini AI
const webSearch = new WebSearch(SEARCH_API_KEY);
const contentFetcher = new ContentFetcher();
const sourceVerifier = new SourceVerifier(geminiAI, webSearch, contentFetcher, cacheManager, errorHandler);
const factChecker = new FactChecker(geminiAI, sourceVerifier, cacheManager, errorHandler);
const claimExtractor = new ClaimExtractor(geminiAI, errorHandler);
const contradictionDetector = new ContradictionDetector(geminiAI, errorHandler);
const confidenceScorer = new ConfidenceScorer(geminiAI);
const threadContextAnalyzer = new ThreadContextAnalyzer(geminiAI, errorHandler);
const interactiveVerifier = new InteractiveVerifier(geminiAI, errorHandler);
const parallelProcessor = new ParallelProcessor(logger);

// Enhanced memory functions
async function loadMemory(userId) {
let doc = await Memory.findOne({ userId });
if (!doc) {
doc = new Memory({ userId, context: [], summary: ‚Äú‚Äù, preferences: ‚Äú‚Äù });
await doc.save();
}
doc.lastActive = new Date();
await doc.save();
return doc;
}

async function saveMemory(userId, context, summary, preferences = null) {
const trimmed = context.slice(-20);
const update = {
context: trimmed,
lastActive: new Date()
};
if (summary) update.summary = summary;
if (preferences !== null) update.preferences = preferences;
await Memory.findOneAndUpdate({ userId }, update, { upsert: true });
}

async function loadChannelMemory(channelId) {
let doc = await ChannelMemory.findOne({ channelId });
if (!doc) {
doc = new ChannelMemory({ channelId, messages: [], recentClaims: [], flaggedMessages: [] });
await doc.save();
}
return doc;
}

async function saveChannelMessage(channelId, messageObj) {
const doc = await loadChannelMemory(channelId);
const updated = [‚Ä¶doc.messages, messageObj].slice(-50); // Keep more context
await ChannelMemory.findOneAndUpdate({ channelId }, { messages: updated });
}

// üìò Enhanced system prompt with fact-checking awareness
const AIPrompt = (date, summary, preferences, factCheckContext = null) => `
You are Arbiter, the wise assistant of The Debate Server Discord community.
You provide logical insights, calm judgment, and philosophical clarity while helping maintain factual accuracy.

Core traits: Direct, succinct, humble, stoic, and committed to truth.
Keep responses brief and focused on key facts.

Today‚Äôs date: ${date}
User summary: ${summary || ‚ÄúNew user‚Äù}
User preferences: ${preferences || ‚ÄúNone‚Äù}

${factCheckContext ? `IMPORTANT: Recent fact-checking context: ${factCheckContext} If you recently flagged misinformation, maintain a helpful and educational tone. Focus on media literacy and encourage source verification rather than confrontation.` : ‚Äò‚Äô}

When appropriate, encourage users to:

- Verify claims with multiple sources
- Consider source credibility and bias
- Think critically about information
- Ask for evidence when making claims

Avoid being preachy - integrate these naturally into conversation.
`;

// üîç Core fact-checking pipeline
async function analyzeMessageForMisinformation(message, userId, channelId) {
try {
logger.info(`Starting fact-check analysis for message from user ${userId}`);

```
// Step 1: Extract potential claims
const claims = await claimExtractor.extractClaims(message.content);

if (!claims || claims.length === 0) {
  logger.info("No verifiable claims found in message");
  return null;
}

logger.info(`Found ${claims.length} potential claims to verify`);

// Step 2: Get thread context
const threadContext = await threadContextAnalyzer.analyzeContext(channelId, message.content);

// Step 3: Process claims in parallel for efficiency
const claimResults = await parallelProcessor.processBatch(
  claims,
  async (claim) => {
    logger.info(`Processing claim: "${claim.substring(0, 100)}..."`);
    
    // Fact-check the claim
    const factCheckResult = await factChecker.verifyClaimMultiStep(claim);
    
    // Check for contradictions in user's message history
    const userDoc = await loadMemory(userId);
    const contradictions = await contradictionDetector.findContradictions(
      claim, 
      userDoc.context.map(c => c.content).join(' ')
    );
    
    return { claim, factCheckResult, contradictions };
  },
  2 // Process 2 claims at a time
);

// Step 4: Analyze overall confidence and determine action
const analysis = await confidenceScorer.analyzeResults(
  claimResults.map(r => r.factCheckResult),
  claimResults.flatMap(r => r.contradictions || [])
);

// Step 5: Save fact-check record
if (analysis.should_flag || analysis.confidence > 0.5) {
  const factCheckRecord = new FactCheck({
    originalMessage: message.content,
    userId: userId,
    channelId: channelId,
    claims: claimResults.map(r => r.claim),
    analysis: analysis,
    timestamp: new Date(),
    confidence: analysis.confidence,
    flagged: analysis.should_flag
  });
  
  await factCheckRecord.save();
  
  // Update user's fact-check history
  await Memory.findOneAndUpdate(
    { userId },
    { $push: { factCheckHistory: factCheckRecord._id } }
  );
}

logger.info(`Fact-check complete. Should flag: ${analysis.should_flag}, Confidence: ${analysis.confidence}`);

return analysis;
```

} catch (error) {
logger.error(‚ÄúFact-checking pipeline error:‚Äù, error);
await errorHandler.handleError(error, {
service: ‚Äòfact-checking-pipeline‚Äô,
userId,
channelId,
messageContent: message.content.substring(0, 100)
});
return null;
}
}

// üéØ Enhanced message processing with Gemini AI
async function generateSummary(context) {
try {
const systemPrompt = ‚ÄúSummarize this user‚Äôs personality, interests, beliefs, and communication patterns based on their recent conversation history. Include any notable claims they‚Äôve made. Be concise and informative.‚Äù;
const userMessages = context.slice(-15).map((m) => `${m.role.toUpperCase()}: ${m.content}`).join(‚Äô\n\n‚Äô);

```
const summary = await geminiAI.generateBackground(userMessages, systemPrompt);
return summary;
```

} catch (error) {
logger.error(‚ÄúSummary generation error:‚Äù, error);
return ‚ÄúUnable to generate user summary‚Äù;
}
}

async function detectUserPreferenceRequest(context, input) {
try {
const systemPrompt = `
You identify if a user is expressing long-term instructions for how they want to be treated.

Examples of preferences:

- ‚Äútalk to me more formally‚Äù
- ‚Äúcall me captain‚Äù
- ‚Äúbe more sarcastic‚Äù
- ‚Äúdon‚Äôt fact-check my messages‚Äù
- ‚Äúremind me to cite sources‚Äù

If there is a persistent preference in the message, reply with the user‚Äôs request in natural language.
If there is no persistent preference, reply exactly with ‚Äúnone‚Äù.
`;

```
const conversationContext = context.slice(-10).map(m => `${m.role.toUpperCase()}: ${m.content}`).join('\n\n');
const prompt = `${conversationContext}\n\nUSER: ${input}\n\nDoes this contain a persistent preference?`;

const response = await geminiAI.generateBackground(prompt, systemPrompt);
const output = response.trim();
return output.toLowerCase() === "none" ? null : output;
```

} catch (err) {
logger.error(‚ÄúPreference detection error:‚Äù, err);
return null;
}
}

// ü§ñ Enhanced Discord Bot Setup
const client = new Client({
intents: [
GatewayIntentBits.Guilds,
GatewayIntentBits.GuildMessages,
GatewayIntentBits.MessageContent,
GatewayIntentBits.DirectMessages,
],
});

// Track processing to avoid duplicate fact-checks
const processingMessages = new Set();

client.on(‚ÄúmessageCreate‚Äù, async (message) => {
if (message.author.bot) return;
if (processingMessages.has(message.id)) return;

processingMessages.add(message.id);

try {
const isMentioned = message.mentions.users.has(client.user.id);
const isRepliedTo = message.reference?.messageId
? (await message.channel.messages.fetch(message.reference.messageId)).author.id === client.user.id
: false;

```
const input = message.content.trim();
const userId = message.author.id;
const channelId = message.channel.id;

// Always save channel message for context
await saveChannelMessage(channelId, {
  username: message.author.username,
  content: input,
  timestamp: new Date(),
  userId: userId
});

// Background fact-checking for all messages (but only respond if flagged)
let factCheckResult = null;
if (input.length > 20) { // Only fact-check substantial messages
  factCheckResult = await analyzeMessageForMisinformation(message, userId, channelId);
}

// Handle fact-checking flags
if (factCheckResult && factCheckResult.should_flag) {
  logger.info(`Misinformation flagged from user ${userId}: ${factCheckResult.reason}`);
  
  // Send educational response
  const educational = `üîç **Media Literacy Note**\n\n${factCheckResult.educational_response}\n\n` +
    `${factCheckResult.sources && factCheckResult.sources.length > 0 ? 
      `**Helpful sources:**\n${factCheckResult.sources.slice(0, 3).map(s => `‚Ä¢ [${s.title}](${s.url})`).join('\n')}` : 
      '**Consider checking multiple reliable sources before sharing claims.**'}\n\n` +
    `*This is an automated fact-checking service to help maintain information quality.*`;
  
  await message.reply(educational);
}

// Regular chat responses (only for mentions/replies)
if (isMentioned || isRepliedTo) {
  const userDoc = await loadMemory(userId);
  const channelDoc = await loadChannelMemory(channelId);
  const userContext = [...userDoc.context, { role: "user", content: input }];
  const channelContext = channelDoc.messages.slice(-10).map((msg) => ({
    role: "user",
    content: `${msg.username}: ${msg.content}`,
  }));

  const newPref = await detectUserPreferenceRequest(userContext, input);
  const updatedPreferences = newPref || userDoc.preferences;

  await message.channel.sendTyping();

  const displayName = message.member?.displayName || message.author.username;
  const currentDate = new Date().toLocaleDateString("en-US", {
    year: "numeric",
    month: "long",
    day: "numeric",
  });

  // Include fact-check context if relevant
  let factCheckContext = null;
  if (factCheckResult) {
    factCheckContext = `Recently analyzed claims in this conversation. Confidence level: ${Math.round(factCheckResult.confidence * 100)}%`;
  }

  // Prepare conversation for Gemini
  const systemPrompt = AIPrompt(currentDate, userDoc.summary, updatedPreferences, factCheckContext);
  const conversationPrompt = [
    ...channelContext.map(msg => msg.content),
    ...userContext.slice(-10).map(msg => `${msg.role.toUpperCase()}: ${msg.content}`)
  ].join('\n\n');

  const reply = await geminiAI.generateResponse(conversationPrompt, systemPrompt);
  await message.reply(`${displayName},\n\n${reply}`);

  const updatedContext = [...userContext, { role: "assistant", content: reply }];
  let updatedSummary = userDoc.summary;

  if (updatedContext.length % 12 === 0) {
    updatedSummary = await generateSummary(updatedContext.slice(-20));
  }

  await saveMemory(userId, updatedContext, updatedSummary, updatedPreferences);
}
```

} catch (err) {
logger.error(‚ÄúMessage processing error:‚Äù, err);
if (isMentioned || isRepliedTo) {
await message.reply(‚ÄúI encountered an issue processing your message. Please try again.‚Äù);
}
} finally {
processingMessages.delete(message.id);
}
});

// Enhanced bot startup
client.on(‚Äúready‚Äù, () => {
console.log(`üü¢ Arbiter online as ${client.user.tag}`);
console.log(`ü§ñ Powered by Google Gemini AI`);
console.log(`üìä Fact-checking services initialized`);
console.log(`üîç Monitoring for misinformation across ${client.guilds.cache.size} servers`);

// Set activity status
client.user.setActivity(‚Äòfor misinformation‚Äô, { type: ‚ÄòWATCHING‚Äô });
});

// Graceful error handling
client.on(‚Äúerror‚Äù, (error) => {
logger.error(‚ÄúDiscord client error:‚Äù, error);
});

process.on(‚ÄòunhandledRejection‚Äô, (reason, promise) => {
logger.error(‚ÄòUnhandled Rejection at:‚Äô, promise, ‚Äòreason:‚Äô, reason);
});

process.on(‚ÄòuncaughtException‚Äô, (error) => {
logger.error(‚ÄòUncaught Exception:‚Äô, error);
process.exit(1);
});

// Periodic cleanup
setInterval(async () => {
try {
// Clean old channel messages
await ChannelMemory.updateMany(
{ lastCleaned: { $lt: new Date(Date.now() - 24 * 60 * 60 * 1000) } },
{
$set: { messages: [], lastCleaned: new Date() },
$unset: { recentClaims: 1 }
}
);

```
// Clear processing cache
processingMessages.clear();

logger.info("Periodic cleanup completed");
```

} catch (error) {
logger.error(‚ÄúCleanup error:‚Äù, error);
}
}, 60 * 60 * 1000); // Every hour

client.login(DISCORD_TOKEN);